{"/fibonacci-backend-cache/backend-cache-coding":{"title":"Backend Cache Coding","data":{"backend-코드-작업#Backend 코드 작업":"","fibonaccicachecontroller#FibonacciCacheController":"FibonacciCacheController\n// ...\r\n@RestController\r\npublic class FibonacciCacheController {\r\n    @Value(\"${fibonacci.language}\") // 1)\r\n    private String language;\r\n\r\n    @Value(\"${fibonacci.api-key}\")  // 1)\r\n    private String apiKey;\r\n\r\n    private final FibonacciResultCacheService fibonacciResultCacheService;\r\n    private final FibonacciCalculateRestClient fibonacciCalculateRestClient;\r\n    private final FibonacciTaskQueue fibonacciTaskQueue;\r\n\r\n    public FibonacciCacheController(\r\n        FibonacciResultCacheService fibonacciResultCacheService,\r\n        FibonacciCalculateRestClient fibonacciCalculateRestClient,\r\n        FibonacciTaskQueue fibonacciTaskQueue\r\n    ){\r\n        this.fibonacciResultCacheService = fibonacciResultCacheService;\r\n        this.fibonacciCalculateRestClient = fibonacciCalculateRestClient;\r\n        this.fibonacciTaskQueue = fibonacciTaskQueue;\r\n    }\r\n\r\n    @GetMapping(\"/fibonacci/{number}\")\r\n    public String getFibonacci(\r\n            @PathVariable(\"number\") int number,\r\n            @RequestParam(value = \"api-key\", required = false) String apiKey\r\n    ){\r\n        if(number > 10){\r\n            if(!this.apiKey.equals(apiKey)){\r\n                throw new ApiKeyNotExistException(\"10 이상의 수에 대한 피보나치 계산은 API KEY 가 필요합니다.\");\r\n            }\r\n        }\r\n\r\n        return fibonacciResultCacheService\r\n                .selectFibonacci(number)\r\n                .map(BigDecimal::toPlainString)\r\n                .orElseGet(() -> {\r\n                    if(number > 1000){\r\n                        final long size = fibonacciTaskQueue.offerTask(number);\r\n                        return switch (language){\r\n                            case \"ko\" -> \"fibonacci(\" + number + \") 계산을 예약합니다. 남은 작업수 = \" + size;\r\n                            case \"en\" -> \"fibonacci(\" + number + \") has been scheduled. Remain task = \" + size;\r\n                            default -> \"Unsupported Language\";\r\n                        };\r\n                    }\r\n\r\n                    return fibonacciCalculateRestClient\r\n                            .requestGetFibonacci(number)\r\n                            .map(result -> {\r\n                                fibonacciResultCacheService.putResult(number, result);\r\n                                return result.toPlainString();\r\n                            })\r\n                            .orElseThrow(() -> new IllegalStateException(\r\n                                    \"피보나치 연산에 문제가 발생했습니다.\"\r\n                            ));\r\n\r\n                });\r\n    }\r\n}\n1) ${fibonacci.language}, ${fibonacci.api-key}\n쿠버네티스 레벨에서 주입한 환경변수입니다. Pod 내에서는 ConfigMap 에 선언한 설정변수를 환경변수로 주입받고, Pod 내에서 Docker Container 로 동작하는 fibonacci-backend-cache 모듈 내에서는 application.yml 파일 내에서 아래와 같이 환경변수를 주입받고 있습니다.\nfibonacci:\r\n  language: ${APP_LANGUAGE:en} # 여기\r\n  api-key: ${API_KEY:hello-welcome} # 여기\r\nspring:\r\n  data:\r\n    redis:\r\n      host: redis-service.default.svc.cluster.local\r\n      port: 6379","fibonacciresultcacheservice#FibonacciResultCacheService":"// ...\r\n@Service\r\npublic class FibonacciResultCacheService {\r\n    private final StringRedisTemplate stringRedisTemplate;\r\n\r\n    public FibonacciResultCacheService(\r\n            StringRedisTemplate stringRedisTemplate\r\n    ){\r\n        this.stringRedisTemplate = stringRedisTemplate;\r\n    }\r\n\r\n    private final String HASH_KEY = \"fibonacci:result-set\";\r\n\r\n    public Optional<BigDecimal> selectFibonacci(int number){\r\n        return getResult(String.valueOf(number))\r\n                .map(str -> new BigDecimal(str));\r\n    }\r\n\r\n    public Optional<String> getResult(String key){\r\n        HashOperations<String, String, String> hashOperations =\r\n                stringRedisTemplate.opsForHash();\r\n\r\n        return Optional\r\n                .ofNullable(hashOperations.get(HASH_KEY, key));\r\n    }\r\n\r\n    public void putResult(int n, BigDecimal result){\r\n        stringRedisTemplate.opsForHash().put(HASH_KEY, String.valueOf(n), result.toPlainString());\r\n    }\r\n}","fibonaccicalculaterestclient#FibonacciCalculateRestClient":"// ...\r\n@Component\r\npublic class FibonacciCalculateRestClient {\r\n    private final RestClient fibonacciClient = RestClient.create();\r\n    public Optional<BigDecimal> requestGetFibonacci(int number) {\r\n        String result = fibonacciClient.get()\r\n                .uri(\"http://fibonacci-backend-web-service:8080/fibonacci?number=\"+number) // 1)\r\n                .retrieve()\r\n                .onStatus(HttpStatusCode::isError, (request, response) -> {\r\n                    throw new RuntimeException(\"invalid server response \"+ response.getStatusText());\r\n                })\r\n                .body(String.class);\r\n\r\n        return Optional.ofNullable(new BigDecimal(result));\r\n    }\r\n}\n1)\n같은 클러스터 내에 같은 namespace 에 존재하는 다른 Deployment 를 호출할 때는 그 Deployment 가 속한 Service 의 이름을 지정하는 것만으로 호출이 가능합니다.\nfibonacci-backend-web-service 는 fibonacci-backend-web-deploy 라는 디플로이먼트의 네트워킹을 위한 서비스입니다.\nfibonacci-backend-deploy는 fibonacci-backend-web 모듈을 Deployment 로 배포하는 리소스입니다. fibonacc-backend-web 모듈은 fibonacci 계산을 Top Down 방식으로 계산하는 /fibonacci API를 가지고 있고, fibonacci-backend-cache 에서 호출합니다.","probe-헬스체크#Probe (헬스체크)":"HealthCheckController\n// ...\r\n\r\n@RestController\r\n@RequestMapping(\"/probe\")\r\npublic class HealthCheckController {\r\n\r\n    private final Logger logger = LoggerFactory.getLogger(HealthCheckController.class);\r\n\r\n    @GetMapping(\"/startup\")\r\n    public String startupCheck(){\r\n        logger.info(\"[startup probe] >>> OK\");\r\n        return \"START UP OK\";\r\n    }\r\n\r\n    @GetMapping(\"/ready\")\r\n    public String readinessCheck(){\r\n        logger.info(\"[readiness probe] >>> OK\");\r\n        return \"READY OK\";\r\n    }\r\n\r\n    @GetMapping(\"/live\")\r\n    public String livenessCheck(){\r\n        logger.info(\"[liveness probe] >>> OK\");\r\n        return \"OK\";\r\n    }\r\n\r\n}"}},"/fibonacci-backend-cache/backend-cache-graceful-shutdown":{"title":"Backend Cache Graceful Shutdown","data":{"graceful-shutdown-처리#Graceful Shutdown 처리":"Graceful Shutdown 시 작업의 종료 통지, 리소스 회수 등을 수행할 때 처리해줄 작업들에 대한 실습입니다."}},"/fibonacci-backend-cache/backend-cache-kustomize":{"title":"Backend Cache Kustomize","data":{"kustomize-overlay-작업#Kustomize Overlay 작업":"코드작업은 정말 빠르게 하고 쉬웠는데, 문서작업은 왜 이렇게 힘든걸까요? ㅠㅠ","깃헙-리포지터리#깃헙 리포지터리":"여기서 정리하는 내용들은 github.com/chagchagchag/fibonacci-backend 내의 fibonacci-backend/k8s/kustomize 디렉터리에 있는 내용들입니다.","secret#Secret":"fibonacci-backend/k8s/kustomize 디렉터리 내의 create-secret.sh 파일에 대한 내용입니다.kustomize 를 적용하기에 앞서서 아래의 내용을 적용해줍니다.\nkubectl -n fibonacci create secret generic fibonacci-cache-secret --from-literal=api-key=abcd-efgh-ijkl-1111","redis#Redis":"fibonacci-backend/k8s/kustomize 디렉터리 내의 create-redis.sh 파일에 대한 내용입니다.\r\nredis 가 설치되어 있지 않다면 아래의 내용을 적용해줍니다.\nkubectl apply -f redis-service.yml\r\nkubectl apply -f redis-pod.yml","fibonacci-backend-cache-의-kustomize-작업#fibonacci-backend-cache 의 kustomize 작업":"대략적인 구조는 이렇습니다.\r\nbase 디렉터리\n기본적인 리소스 들의 정의 파일들을 둡니다.\n이렇게 정의된 파일들을 base 디렉터리 내에서 kustomize 하는 역할을 하는 파일은 kustomization.yml 입니다.\noverlay 디렉터리\noverlay/develop 디렉터리\nbase/kustomization.yml 파일에서 조합한 리소스파일 들에서 tag, namespace를 develop 에 맞게끔 덮어쓰는 작업을 합니다.\noverlay/develop/kustomization.yml 파일에서 따로 develop 버전에 맞도록 재정의한 namespace, tag 등이 적용되어 재정의됩니다.\noverlay/production 디렉터리\nbase/kustomization.yml 파일에서 조합한 리소스파일 들에서 tag, namespace를 production 에 맞게끔 덮어쓰는 작업을 합니다.\noverlay/production/kustomization.yml 파일에서 따로 production 버전에 맞도록 재정의한 namespace, tag 등이 적용되어 재정의됩니다.\n이렇게 작성한 파일들은 아래와 같이 적용합니다.\r\ndevelop Phase 에 배포할 경우\n$ cd k8s/kustomize/fibonacci-backend-cache\r\n$ cd overlay/develop\r\n$ kubectl kustomize ./ | kubectl apply -f -\nproduction Phase 에 배포할 경우\n$ cd k8s/kustomize/fibonacci-backend-web\r\n$ cd overlay/develop\r\n$ kubectl kustomize ./ | kubectl apply -f -\nkubectl kustomize ./ 명령은 현재 디렉터리 내의 kustomization.yml 파일에 정의한 리소스들을 기준으로 각각의 리소스를 조합해서 리소스 정의서를 만들어냅니다. 이렇게 해서 명령창에서 kubectl kustomize ./ 을 실행하면 리소스 정의 yml 이 생성되니다.kubectl apply -f 앞에 붙은 - 의 의미는 표준 입력을 의미합니다. kubectl kustomize ./ 을 통해서 조합한 리소스 정의에 대한 yaml 문자열이 입출력 파이프라인 명령어인 | 을 통해 유입되고 이 파이프라인을 통해 kubectl kustomize ./ 명령어에 인자값으로 전달됩니다.","리소스-파일들#리소스 파일들":"","base#base":"","basekustomizationyml#base/kustomization.yml":"apiVersion: kustomize.config.k8s.io/v1beta1\r\nkind: Kustomization\r\nresources:\r\n- fibonacci-cache-namespace.yml\r\n- fibonacci-cache-ingress.yml\r\n- fibonacci-cache-config.yml\r\n- fibonacci-cache-local-storage.yml\r\n- fibonacci-cache-log-pvc.yml\r\n- fibonacci-cache-deploy.yml\r\n- fibonacci-cache-service.yml","basefibonacci-cache-configyml#base/fibonacci-cache-config.yml":"apiVersion: v1\r\nkind: ConfigMap\r\nmetadata:\r\n  name: fibonacci-cache-config\r\n  namespace: fibonacci\r\ndata:\r\n  language: \"ko\"","basefibonacci-cache-ingressyml#base/fibonacci-cache-ingress.yml":"apiVersion: networking.k8s.io/v1\r\nkind: Ingress\r\nmetadata:\r\n  name: fibonacci-ingress\r\n  namespace: fibonacci\r\nspec:\r\n  rules:\r\n    - http:\r\n        paths:\r\n          - pathType: Prefix\r\n            path: /fibonacci\r\n            backend:\r\n              service:\r\n                name: fibonacci-backend-cache-service\r\n                port:\r\n                  number: 8080","basefibonacci-cache-serviceyml#base/fibonacci-cache-service.yml":"apiVersion: v1\r\nkind: Service\r\nmetadata:\r\n  name: fibonacci-backend-cache-service\r\n  namespace: fibonacci\r\nspec:\r\n  selector:\r\n    app: fibonacci-backend-cache\r\n  ports:\r\n    - protocol: TCP\r\n      port: 8080","basefibonacci-cache-deployyml#base/fibonacci-cache-deploy.yml":"apiVersion: apps/v1\r\nkind: Deployment\r\nmetadata:\r\n  name: fibonacci-backend-cache-deploy\r\n  namespace: fibonacci\r\nspec:\r\n  replicas: 2\r\n  strategy:\r\n    type: RollingUpdate\r\n    rollingUpdate:\r\n      maxSurge: 1\r\n      maxUnavailable: 0\r\n  selector:\r\n    matchLabels:\r\n      app: fibonacci-backend-cache\r\n  template:\r\n    metadata:\r\n      labels:\r\n        app: fibonacci-backend-cache\r\n    spec:\r\n      terminationGracePeriodSeconds: 60\r\n      volumes:\r\n        - name: cache-volume\r\n          emptyDir:\r\n            medium: Memory\r\n        - name: log-volume\r\n          persistentVolumeClaim:\r\n            claimName: cache-log-storage-claim\r\n      containers:\r\n        - name: fibonacci\r\n          image: chagchagchag/fibonacci-backend-cache:0.0.1\r\n          imagePullPolicy: Always\r\n          volumeMounts:\r\n            - mountPath: /fibonacci/logs\r\n              name: log-volume\r\n            - mountPath: /fibonacci/cache\r\n              name: cache-volume\r\n          env:\r\n            - name: APP_LANGUAGE\r\n              valueFrom:\r\n                configMapKeyRef:\r\n                  name: fibonacci-cache-config\r\n                  key: language\r\n            - name: API_KEY\r\n              valueFrom:\r\n                secretKeyRef:\r\n                  name: fibonacci-cache-secret\r\n                  key: api-key\r\n          lifecycle:\r\n            preStop:\r\n              exec:\r\n                command: [\"/bin/sh\",\"-c\",\"sleep 10\"]\r\n          readinessProbe:\r\n            httpGet:\r\n              path: /probe/healthcheck\r\n              port: 8080\r\n            initialDelaySeconds: 15\r\n            periodSeconds: 1\r\n            successThreshold: 2\r\n            failureThreshold: 3\r\n          livenessProbe:\r\n            httpGet:\r\n              path: /probe/healthcheck\r\n              port: 8080\r\n            initialDelaySeconds: 15\r\n            periodSeconds: 1\r\n            failureThreshold: 7","basefibonacci-cache-namespaceyml#base/fibonacci-cache-namespace.yml":"apiVersion: v1\r\nkind: Namespace\r\nmetadata:\r\n  name: fibonacci-cache","basefibonacci-cache-log-pvcyml#base/fibonacci-cache-log-pvc.yml":"apiVersion: v1\r\nkind: PersistentVolumeClaim\r\nmetadata:\r\n  name: cache-log-storage-claim\r\n  namespace: fibonacci\r\nspec:\r\n  # kubectl get sc 명령을 통해 나타나는 StorageClass 중 하나를 선택했다.\r\n  # 로컬에서는 kind 클러스터 버전에 따라 standard 가 나올수도 있고 local-storage 가 나올수도 있다.\r\n  storageClassName: standard\r\n  accessModes:\r\n    - ReadWriteOnce\r\n  resources:\r\n    requests:\r\n      storage: 100Mi","overlay#overlay":"overlay 에 정의하는 kustomization.yml 에는 주로 배포 Phase 에 맞는 환경, 이미지 명, 태그, 볼륨 명, 각종 환경 변수 등을 덮어쓰는 내용 들을 정의합니다.","overlaydevelopkustomizationyml#overlay/develop/kustomization.yml":"apiVersion: kustomize.config.k8s.io/v1beta1\r\nkind: Kustomization\r\nresources:\r\n  - ../../base\r\nimages:\r\n  - name: chagchagchag/fibonacci-backend-cache\r\n  - newName: chagchagchag/fibonacci-backend-cache\r\n  - newTag: 0.0.1-fibonacci-backend-cache.01\r\nnamespace: fibonacci-cache-develop","overlayproductionkustomizationyml#overlay/production/kustomization.yml":"apiVersion: kustomize.config.k8s.io/v1beta1\r\nkind: Kustomization\r\nresources:\r\n  - ../../base\r\nimages:\r\n  - name: chagchagchag/fibonacci-backend-cache\r\n  - newName: chagchagchag/fibonacci-backend-cache\r\n  - newTag: 0.0.1-fibonacci-backend-cache.01\r\nnamespace: fibonacci-cache-production","리소스-파일들-1#리소스 파일들":"설명 꽤 복잡한돼 힘든돼 아 정말..."}},"/fibonacci-backend-cache/backend-cache-jib-build":{"title":"Backend Cache Jib Build","data":{"gradle-jib-빌드-정의-이미지-생성-푸시#Gradle Jib 빌드 정의, 이미지 생성, 푸시":"도커이미지를 빌드,푸시하는 방식에 대해 정리해봅니다. Gradle Jib 빌드 방식에 대해서 정리하지만, Dockerfile 로 빌드하는 방식에 대해서도 문서의 마지막에 추가로 정리해두겠습니다.","참고#참고":"github.com/jib/jib-gradle-plugin\ngithub.com/GoogleContainerTools/jib","javakotlin-애플리케이션의-도커이미지-빌드-방식#Java/Kotlin 애플리케이션의 도커이미지 빌드 방식":"Java/Kotlin 애플리케이션의 Gradle 빌드 시 두가지를 선택할 수 있습니다\nGradle Jib 플러그인을 사용하는 빌드 & 푸시\nDockerfile 정의, Shell Script 를 이용한 빌드 & 푸시\n두 방법 중에는 일반적으로 Gradle Jib 을 이용한 방식이 많이 사용되는 편입니다.","gradle-jib-으로-docker-이미지-빌드--푸시#Gradle Jib 으로 Docker 이미지 빌드 & 푸시":"","plugin-추가#plugin 추가":"plugins {\r\n    // ...\r\n\tid 'com.google.cloud.tools.jib' version '3.4.0'\r\n}\n코틀린 DSL의 build.gradle.kts 파일에서는 아래와 같이 작성합니다.\nplugins {\r\n  // ...\r\n  id(\"com.google.cloud.tools.jib\") version \"3.4.0\"\r\n  // ...\r\n}","빌드스크립트-작성#빌드스크립트 작성":"jib {\r\n\tfrom {\r\n\t\timage = \"amazoncorretto:17\"\r\n\t}\r\n\r\n\tto{\r\n\t\timage = \"chagchagchag/fibonacci-backend-cache\"\r\n\t\ttags = [\"0.0.1\", \"0.0.1.fibonacci-backend-cache.01\", \"latest\" ]\r\n\t}\r\n\r\n\tcontainer{\r\n\t\tcreationTime = \"USE_CURRENT_TIMESTAMP\"\r\n\t}\r\n}\n위의 빌드스크립트의 경우 코틀린 문법과 다른 부분이 없기에 코틀린 DSL 의 build.gradle.kts 파일을 작성시에도 위의 내용을 그대로 사용하면 됩니다.젠킨스나 Github CI에서 빌드하는 것이 아닌 경우 개발자의 PC에 따라 CPU 가 달라지는 것으로 인해 애플 M1 등 여러가지 빌드 옵션을 직접 추가하거나 이런 작업들이 필요한 경우가 있습니다.이런 경우 jib 내의 from 구문에 아래와 같은 내용을 작성해주시면 됩니다.\n// ...\r\n\r\njib {\r\n    from {\r\n        image = \"amazoncorretto:17\"\r\n\r\n        platforms {\r\n            platform{\r\n                architecture = \"arm64\"\r\n                os = \"linux\"\r\n            }\r\n        }\r\n    }\r\n}\r\n\r\n// ...\n회사에서 실제 개발 작 시 필요한 내용들을 정의할 때 세부적인 내용들이 많이 필요할 수 있는데 자세한 설명은 github.com/jib/jib-gradle-plugin 에서 확인할 수 있습니다.","빌드--push#빌드 & Push":"이렇게 작성한 build 스크립트는 gradle 명령어로 빌드할 수도 있고, intellij 에서 jib 태스크를 실행해서 도커이미지를 빌드 후 푸시할 수도 있습니다.참고로 개발 PC에서 빌드 실행 시 Docker Desktop 이 실행 중이어야 합니다.","intellij-내에서-jib-태스크-실행#intellij 내에서 jib 태스크 실행":"인텔리제이 내에서는 아래와 같이 jib 태스크 버튼을 눌러서 태스크를 실행해주시면 됩니다.","gradlew-명령어로-실행#gradlew 명령어로 실행":"gradlew 명령어로 실행하는 것은 아래와 같이 하면 됩니다.\n./gradlew fibonacci-backend-cache:jib","컨테이너-이미지-동작-확인#컨테이너 이미지 동작 확인":"도커 이미지 pull (만약 로컬에 이미지가 없다면)\n$ docker pull chagchagchag/fibonacci-backend-cache:0.0.1\n도커 이미지 구동\ndocker container run --rm -d -p 8080:8080 --name fibonacci-backend-cache-local chagchagchag/fibonacci-backend-cache:0.0.1\r\n\r\n동작 확인\n$ curl http://localhost:8080/probe/healthcheck\r\nOK\n종료\ndocker container stop fibonacci-backend-cache-local\r\n\r\nfibonacci-backend-cache-local","dockerfile-로-docker-이미지-빌드--푸시#Dockerfile 로 Docker 이미지 빌드 & 푸시":"","dockerfile-정의-빌드--푸시#Dockerfile 정의, 빌드 & 푸시":"Dockerfile_simple\nFROM amazoncorretto:17\r\nWORKDIR deploy\r\nCOPY build/libs/fibonacci_backend_cache-0.0.1.jar app.jar\r\nENTRYPOINT [\"java\", \"-jar\", \"app.jar\"]\n이미지 빌드\ndocker build -f Dockerfile_simple --tag chagchagchag/fibonacci-backend-cache-simple:0.0.1 .\n컨테이너 구동\n$ docker container run --name fibonacci-backend-cache-simple --rm -d -p 8080:8080 chagchagchag/fibonacci-backend-cache-simple:0.0.1\r\n\r\n\r\n## 확인\r\n$ docker container ls\r\nCONTAINER ID   IMAGE                                               COMMAND               CREATED         STATUS\r\nPORTS                    NAMES\r\ncf160b8e1ae2   chagchagchag/fibonacci-backend-cache-simple:0.0.1   \"java -jar app.jar\"   6 seconds ago   Up 4 seconds   0.0.0.0:8080->8080/tcp   fibonacci-backend-cache-simple\nAPI 확인\n$ curl http://localhost:8080/probe/healthcheck\r\nOK\n종료&삭제\n$ docker container stop fibonacci-backend-cache-simple\r\nfibonacci-backend-cache-simple","이미지-리포지터리#이미지 리포지터리":"예전의 레거시 개발 방식에서는 Docker 이미지라는 것이 필요가 없었습니다. 현재는 Docker Container 방식의 이미지를 구동하는 방식이 대중화되어 있습니다. 이때 이미지 리포지터리에 개발버전이 잘못 Push 될 수 있는 경우가 있습니다.이런 이유로 가급적이면 개발 용도의 이미지 리포지터리와 Deploy (배포) 전용 이미지 리포지터리를 따로 운영해서 Github Action 등에서만 사용하는 Deploy 전용 이미지 리포지터리를 사용하는 것을 권장드립니다.\n보통 이미지 리포지터리는 S3 방식으로 운영되는 것으로 알고 있습니다. 따라서 AWS에서 ECR 을 운영,개발 용도로 분리해서 사용한다고 하더라도 용량에 큰 부담도 없고 비용이 그렇게 크게 발생하지는 않을 듯 해보입니다."}},"/fibonacci-backend-cache/backend-cache-k8s-yaml":{"title":"Backend Cache K8s Yaml","data":{"k8s-리소스-정의--로컬-k8s-확인#k8s 리소스 정의 & 로컬 k8s 확인":"시크릿 리소스를 정의하고 사용하는 부분에서는 api-key 를 시크릿에 정의해서 사용합니다. 사실 api-key 를 Secret 에서 정의해두고 단 하나의 api-key 만으로 검사를 한다는 것은 조금 이상해보일 수도 있고 언뜻 예제가 이해가 안갈 수 있습니다.하지만, fibonacci-backend-cache 에서 다양한 쿠버네티스 리소스를 모두 다뤄보려 하다보니 시크릿을 사용하는 기능을 추가해서 억지로 끼워맞췄다는 점을 이해해주시기 바랍니다.","들어가기-전에#들어가기 전에..":"이번 페이지는 ArgoCD나 이런 것들을 설치하지 않은 간단한 버전의 클러스터를 기준으로 리소스들을 kubectl 로 하나 하나 만들어가면서 테스트해가면서 기능들을 완성하는 과정을 설명하기 위한 것이 목적입니다.이번에 사용할 클러스터 정의는 cluster/single-cluster.yml 에 있고, 쉘스크립트는 cluster/create-single-cluster.sh 입니다.","namespace-정의#namespace 정의":"예제 테스트를 위한 namespace를 정의합니다. namespace 는 fibonacci 입니다.\n$ kubectl create ns fibonacci\r\nnamespace/fibonacci created","secret-정의#Secret 정의":"먼저 api 키를 정의합니다.\nkubectl -n fibonacci create secret generic fibonacci-backend-cache-secret --from-literal=api-key=abcd-efgh-ijkl-1111\n이렇게 생성한 시크릿은 아래와 같이 확인 가능합니다.\nkubectl -n fibonacci get secret fibonacci-backend-cache-secret -o yaml\r\n...\r\n\r\n\r\napiVersion: v1\r\ndata:\r\n  api-key: YWJjZC1lZmdoLWlqa2wtMTExMQ==\r\nkind: Secret\r\nmetadata:\r\n  creationTimestamp: \"2024-01-26T04:13:56Z\"\r\n  name: fibonacci-backend-cache-secret\r\n  namespace: fibonacci\r\n  resourceVersion: \"6919\"\r\n  uid: 2f641720-ee50-4223-8120-639ac984524c\r\ntype: Opaque\n만약 이미 배포되어있는 secret 내의 속성값의 디코딩 된 실제 값을 알고 싶다면 아래와 같이 base64 decoding 을 해주면 됩니다.\n$ echo \"YWJjZC1lZmdoLWlqa2wtMTExMQ==\" | base64 -d\r\nabcd-efgh-ijkl-1111\n혹시 평문 문자열이 시크릿 안에 들어갔을 때 어떻게 변하는지 확인하고 싶다면 아래와 같이 -n 옵션을 주어서 개행문자를 제거한 문자열에 대해 base64 인코딩을 해줍니다.\n$ echo -n \"abcd-efgh-ijkl-1111\" | base64\r\nYWJjZC1lZmdoLWlqa2wtMTExMQ==\n-n 옵션이 없으면 개행문자가 추가된 상태로 출력됩니다.","configmap-정의#ConfigMap 정의":"이번에는 ConfigMap 을 정의해봅니다.\r\nfibonacci-cache-config.yml\napiVersion: v1\r\nkind: ConfigMap\r\nmetadata:\r\n  name: fibonacci-cache-config\r\n  namespace: fibonacci\r\ndata:\r\n  language: \"ko\"\ndata.language\ndata.language 라는 속성에 대한 값으로 ko 라는 값을 지정했습니다.\n이렇게 지정한 configmap 을 클러스터 내에 리소스로 생성되게끔 kubectl 로 요청해봅니다.\n$ kubectl apply -f fibonacci-cache-config.yml\r\nconfigmap/fibonacci-cache-config created\n생성되었는지 확인\n$ kubectl -n fibonacci get configmap fibonacci-cache-config\r\nNAME                     DATA   AGE\r\nfibonacci-cache-config   1      153m\r\n\r\n$ kubectl -n fibonacci get configmap fibonacci-cache-config -o yaml\r\napiVersion: v1\r\ndata:\r\n  language: ko\r\nkind: ConfigMap\r\nmetadata:\r\n  annotations:\r\n    kubectl.kubernetes.io/last-applied-configuration: |\r\n      {\"apiVersion\":\"v1\",\"data\":{\"language\":\"ko\"},\"kind\":\"ConfigMap\",\"metadata\":{\"annotations\":{},\"name\":\"fibonacci-cache-config\",\"namespace\":\"fibonacci\"}}\r\n  creationTimestamp: \"2024-01-26T04:34:48Z\"\r\n  name: fibonacci-cache-config\r\n  namespace: fibonacci\r\n  resourceVersion: \"8711\"\r\n  uid: 98d6a65b-4eeb-4ca5-8f0c-c23ac35bb479","pv-pvc-정의#PV, PVC 정의":"pv, pvc 를 이용해서 로그를 파일로 작성하는 예제입니다\npv, pvc에 대해 궁금한 점들이 있다면 아래의 문서들을 참고해주세요.\nPV, PVC\nStorageClass","pvc#PVC":"local-storage 타입의 StorageClass 로 정의한 볼륨을 마운트하는 예제입니다.\napiVersion: v1\r\nkind: PersistentVolumeClaim\r\nmetadata:\r\n  name: cache-log-storage-claim\r\n  namespace: fibonacci\r\nspec:\r\n  # kubectl get sc 명령을 통해 나타나는 StorageClass 중 하나를 선택했다.\r\n  # 로컬에서는 kind 버전에 따라 standard 가 나올수도 있고 local-storage 가 나올수도 있다.\r\n  storageClassName: standard\r\n  accessModes:\r\n    - ReadWriteOnce\r\n  resources:\r\n    requests:\r\n      storage: 100Mi\nmetadata.name : 스토리지 클래스 명\nspec.storageClassName\n사용하는 클러스터에 따라 local-storage 의 종류가 다르게 나옵니다. 꼭 컴퓨터에서 kubectl get sc 명령을 통해서 어떤 storage class 명으로 등록되어있는지 조회해보고 등록되어 있는 스토리지 클래스명을 사용하시면 됩니다.\n예제용도이고 로컬에서 구동하는 예제이기에 약식으로  local-storage 기반으로 구성했습니다. 실무에서는 NFS 또는 EBS 를 사용하는 경우가 더 많습니다.","deployment-정의#Deployment 정의":"apiVersion: apps/v1\r\nkind: Deployment\r\nmetadata:\r\n  name: fibonacci-backend-cache-deploy\r\n  namespace: fibonacci\r\nspec:\r\n  replicas: 2\r\n  strategy:\r\n    type: RollingUpdate\r\n    rollingUpdate:\r\n      maxSurge: 1\r\n      maxUnavailable: 0\r\n  selector:\r\n    matchLabels:\r\n      app: fibonacci-backend-cache\r\n  template:\r\n    metadata:\r\n      labels:\r\n        app: fibonacci-backend-cache\r\n    spec:\r\n      terminationGracePeriodSeconds: 60\r\n      volumes:\r\n        - name: cache-volume\r\n          emptyDir:\r\n            medium: Memory\r\n        - name: log-volume\r\n          persistentVolumeClaim:\r\n            claimName: cache-log-storage-claim\r\n      containers:\r\n        - name: fibonacci\r\n          image: chagchagchag/fibonacci-backend-cache:0.0.1\r\n          imagePullPolicy: Always\r\n          volumeMounts:\r\n            - mountPath: /fibonacci/logs\r\n              name: log-volume\r\n            - mountPath: /fibonacci/cache\r\n              name: cache-volume\r\n          env:\r\n            - name: APP_LANGUAGE\r\n              valueFrom:\r\n                configMapKeyRef:\r\n                  name: fibonacci-cache-config\r\n                  key: language\r\n            - name: API_KEY\r\n              valueFrom:\r\n                secretKeyRef:\r\n                  name: fibonacci-cache-secret\r\n                  key: api-key\r\n          lifecycle:\r\n            preStop:\r\n              exec:\r\n                command: [\"/bin/sh\",\"-c\",\"sleep 10\"]\r\n          readinessProbe:\r\n            httpGet:\r\n              path: /probe/healthcheck\r\n              port: 8080\r\n            initialDelaySeconds: 15\r\n            periodSeconds: 1\r\n            successThreshold: 2\r\n            failureThreshold: 3\r\n          livenessProbe:\r\n            httpGet:\r\n              path: /probe/healthcheck\r\n              port: 8080\r\n            initialDelaySeconds: 15\r\n            periodSeconds: 1\r\n            failureThreshold: 7\nspec.volumes 내에 volume 을 하나 추가해줬습니다.\nvolume 의 이름(name)은 log-volume 이라고 정의해줬고, persistentVolumeClame.clameName 을 지정해서 사용하려는 PersistentVolumeClaim 의 이름을 명시했습니다.","service-정의#Service 정의":"지금까지 만든 애플리케이션은 Pod 를 ReplicaSet 단위로 구동하는 Deployment, 볼륨 용도의 PV,PVC, 환경변수를 보관하는 ConfigMap, API Key 를 저장하기 위한 Secret 이라는 리소스를 두루 사용했습니다.이렇게 만든 애플리케이션에서 Deployment를 클러스터 안에서 네트워킹을 통해 접근할 수 있는 개체로 만드는 방법은 Service 리소스를 정의하는 것입니다.Service 는 Nodeport, ClusterIP 등과 같은 것들이 있고, 자세한 내용은 이번 Github Page 에서 정리하기에는 내용이 다소 길기에 TODO - http://chagchagchag.github.io/docs-k8s-resources 에 정리해두기로 했습니다. 개념 설명은 http://chagchagchag.github.io/docs-k8s-resources 을 참고해주시기 바랍니다.\napiVersion: v1\r\nkind: Service\r\nmetadata:\r\n  name: fibonacci-backend-cache-service\r\n  namespace: fibonacci\r\nspec:\r\n  selector:\r\n    app: fibonacci-backend-cache\r\n  ports:\r\n    - protocol: TCP\r\n      port: 8080\n간단한 ClusterIP 에 대한 정의입니다. 쿠버네티스는 서비스의 타입을 별도로 지정하지 않으면 디폴트 설정으로 ClusterIP 타입으로 정의됩니다. Cluster IP 라는 단어 그대로 Cluster 내에서의 IP 를 의미하며, 클러스터 내에서만 식별이 가능한 IP 입니다.\n위에서 작성한 Cluster IP 서비스의 이름은 fibonacci-backend-cache-service 입니다. 그리고 spec.selector.app 에 유입/유출 네트워크를 연결해줄 Deployment 를 연결해줍니다. 위의 예제에서는 Service 가 fibonacci-backend-cache 라는 이름의 Deployment 를 연결해주고 있고, 연결할 TCP 포트는 8080 포트임을 명시하고 있습니다.","ingress-정의#ingress 정의":"ingress 의 역할은 80 포트 또는 443 포트로 유입되는 트래픽을 Service 타입에 바인딩해주는 역할을 합니다. \n만약 클러스터를 외부 트래픽에 대해 80, 443 포트 외의 포트를 개방하고 싶다면 Ingress 대신 NodePort 를 사용하면 됩니다. NodePort 는 30000 ~ 32768 범위의 포트를 허용가능합니다.\napiVersion: networking.k8s.io/v1\r\nkind: Ingress\r\nmetadata:\r\n  name: fibonacci-ingress\r\n  namespace: fibonacci\r\nspec:\r\n  rules:\r\n    - http:\r\n        paths:\r\n          - pathType: Prefix\r\n            path: /fibonacci\r\n            backend:\r\n              service:\r\n                name: fibonacci-backend-cache-service\r\n                port:\r\n                  number: 8080","리소스-정의-yaml-파일-통합#리소스 정의 YAML 파일 통합":"kustomize 를 사용한다면 이런 작업은 필요가 없겠지만, 단순 yaml 파일 기반으로 작업한다면 위의 yaml 파일들을 모두 순차적으로 실행시켜줘야 합니다.이렇게 하면 조금 귀찮아지기에 여기에서는 위의 모든 yaml 리소스 정의를 하나의 파일로 합친 리소스 정의 yaml 을 작성한 부분을 아래에 남겨둡니다.\napiVersion: v1\r\nkind: Namespace\r\nmetadata:\r\n  name: fibonacci\r\n---\r\napiVersion: v1\r\nkind: PersistentVolumeClaim\r\nmetadata:\r\n  name: cache-log-storage-claim\r\n  namespace: fibonacci\r\nspec:\r\n  # kubectl get sc 명령을 통해 나타나는 StorageClass 중 하나를 선택했다.\r\n  # 로컬에서는 kind 버전에 따라 standard 가 나올수도 있고 local-storage 가 나올수도 있다.\r\n  storageClassName: standard\r\n  accessModes:\r\n    - ReadWriteOnce\r\n  resources:\r\n    requests:\r\n      storage: 100Mi\r\n---\r\napiVersion: apps/v1\r\nkind: Deployment\r\nmetadata:\r\n  name: fibonacci-backend-cache-deploy\r\n  namespace: fibonacci\r\nspec:\r\n  replicas: 2\r\n  strategy:\r\n    type: RollingUpdate\r\n    rollingUpdate:\r\n      maxSurge: 1\r\n      maxUnavailable: 0\r\n  selector:\r\n    matchLabels:\r\n      app: fibonacci-backend-cache\r\n  template:\r\n    metadata:\r\n      labels:\r\n        app: fibonacci-backend-cache\r\n    spec:\r\n      terminationGracePeriodSeconds: 60\r\n      volumes:\r\n        - name: cache-volume\r\n          emptyDir:\r\n            medium: Memory\r\n        - name: log-volume\r\n          persistentVolumeClaim:\r\n            claimName: cache-log-storage-claim\r\n      containers:\r\n        - name: fibonacci\r\n          image: chagchagchag/fibonacci-backend-cache:0.0.1\r\n          imagePullPolicy: Always\r\n          volumeMounts:\r\n            - mountPath: /fibonacci/logs\r\n              name: log-volume\r\n            - mountPath: /fibonacci/cache\r\n              name: cache-volume\r\n          env:\r\n            - name: APP_LANGUAGE\r\n              valueFrom:\r\n                configMapKeyRef:\r\n                  name: fibonacci-cache-config\r\n                  key: language\r\n            - name: API_KEY\r\n              valueFrom:\r\n                secretKeyRef:\r\n                  name: fibonacci-cache-secret\r\n                  key: api-key\r\n          lifecycle:\r\n            preStop:\r\n              exec:\r\n                command: [\"/bin/sh\",\"-c\",\"sleep 10\"]\r\n          readinessProbe:\r\n            httpGet:\r\n              path: /probe/healthcheck\r\n              port: 8080\r\n            initialDelaySeconds: 15\r\n            periodSeconds: 1\r\n            successThreshold: 2\r\n            failureThreshold: 3\r\n          livenessProbe:\r\n            httpGet:\r\n              path: /probe/healthcheck\r\n              port: 8080\r\n            initialDelaySeconds: 15\r\n            periodSeconds: 1\r\n            failureThreshold: 7\r\n---\r\napiVersion: v1\r\nkind: Service\r\nmetadata:\r\n  name: fibonacci-backend-cache-service\r\n  namespace: fibonacci\r\nspec:\r\n  selector:\r\n    app: fibonacci-backend-cache\r\n  ports:\r\n    - protocol: TCP\r\n      port: 8080\r\n---\r\napiVersion: networking.k8s.io/v1\r\nkind: Ingress\r\nmetadata:\r\n  name: fibonacci-ingress\r\n  namespace: fibonacci\r\nspec:\r\n  rules:\r\n    - http:\r\n        paths:\r\n          - pathType: Prefix\r\n            path: /fibonacci\r\n            backend:\r\n              service:\r\n                name: fibonacci-backend-cache-service\r\n                port:\r\n                  number: 8080\n이제 kubectl 을 통해 적용해봅니다.\n$ kubectl apply -f fibonacci-cache.yml\r\nnamespace/fibonacci created\r\npersistentvolumeclaim/cache-log-storage-claim created\r\ndeployment.apps/fibonacci-backend-cache-deploy created\r\nservice/fibonacci-backend-cache-service created\r\ningress.networking.k8s.io/fibonacci-ingress created\n생성된 리소스들을 확인해봅니다.\n$ kubectl -n fibonacci get all\r\nNAME                                                  READY   STATUS                       RESTARTS   AGE\r\npod/fibonacci-backend-cache-deploy-57558f6b5d-65kbl   0/1     CreateContainerConfigError   0          32s\r\npod/fibonacci-backend-cache-deploy-57558f6b5d-8274h   0/1     CreateContainerConfigError   0          32s\r\n\r\nNAME                                      TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)    AGE\r\nservice/fibonacci-backend-cache-service   ClusterIP   10.96.29.34   <none>        8080/TCP   32s\r\n\r\nNAME                                             READY   UP-TO-DATE   AVAILABLE   AGE\r\ndeployment.apps/fibonacci-backend-cache-deploy   0/2     2            0           32s\r\n\r\nNAME                                                        DESIRED   CURRENT   READY   AGE\r\nreplicaset.apps/fibonacci-backend-cache-deploy-57558f6b5d   2         2         0       32s\n생성한 리소스들을 삭제하려면 아래와 같이 kubectl delete -f  를 해줍니다.\n$ kubectl delete -f fibonacci-cache.yml\r\nnamespace \"fibonacci\" deleted\r\npersistentvolumeclaim \"cache-log-storage-claim\" deleted\r\ndeployment.apps \"fibonacci-backend-cache-deploy\" deleted\r\nservice \"fibonacci-backend-cache-service\" deleted\r\ningress.networking.k8s.io \"fibonacci-ingress\" deleted"}},"/fibonacci-backend-cache/backend-cache-perf-test":{"title":"Backend Cache Perf Test","data":{"부하테스트#부하테스트":"Unit 테스트는 아니고, 성능테스트 결과를 문서로 작성합니다.예를 들어, Shell Script 를 통해 1000개 이상의 요청에 대해 load가 어떻게 분산되는지 등 이런 내용들에 대한 스크린 샷 등으로 문서화 합니다."}},"/setup/deploy-environment":{"title":"Deploy Environment","data":{"배포환경#배포환경":"","kustomize#Kustomize":"develop, production 사이에서 달라지는 부분들에 대해 kustomize 의 cross-cut, base/overlay 기능을 사용합니다.","argocd-argo-rollouts#ArgoCD, Argo Rollouts":"kustomize 로 구성된 yaml 리소스 정의 파일을 기반으로 일반적인 Rolling Update 방식의 단순배포를 구성하고 배포 과정을 확인해봅니다.\n이 외에도 Blue/Green, Canary 무중단 배포 방식 역시 Argo Rollouts 를 이용해 실습으로 진행해봅니다."}},"/fibonacci-backend-cache/introduce-fibonacci-backend-cache":{"title":"Introduce Fibonacci Backend Cache","data":{"소개#소개":"fibonacci-backend-cache 백엔드 애플리케이션의 개발 과정을 정리하는 카테고리입니다."}},"/":{"title":"Introduction","data":{"":"fibonacci-backend 프로젝트 문서 페이지\nGithub : github.com/chagchagchag/fibonacci-backend\n프로젝트 문서 : chagchagchag.github.io/docs-fibonacci-backend\n구버전 문서 : chagchagchag.github.io/fibonacci-backend-docs/\nSpring Boot 기반의 k8s 애플리케이션을 어떻게 개발해나가는지 매뉴얼을 정리"}},"/setup/redis-environment":{"title":"Redis Environment","data":{"redis-환경설정#Redis 환경설정":""}},"/setup/local-k8s-setup":{"title":"Local K8s Setup","data":{"로컬-k8s-셋업#로컬 k8s 셋업":"","notice#Notice":"아래에서 진행하는 모든 내용들은 chagchagchag/fibonacci-backend 을 Clone 받은 후에 진행합니다.","설치-스크립트#설치 스크립트":"로컬 환경에 kind 클러스터 설치를 setup.sh 파일 하나를 실행하는 것으로 가능하게 하는 방법입니다. 아래와 같은 명령을 실행합니다.\ncd cluster\r\nsource setup.sh\n아래에서부터는 Cluster 정의가 어떻게 되는지, ArgoCD가 NodePort 로 어떻게 접속하는지, API 가 어떤 Service 에 붙어서 이 Service 를 어떤 ingress 에서 처리하는지를 정의합니다.","argocd-없이-백엔드-애플리케이션만-테스트해볼때#ArgoCD 없이 백엔드 애플리케이션만 테스트해볼때":"ArgoCD 까지 모두 띄워둔 후 작업을 하기에는 개발작업만 할 때에는 조금 부담스럽습니다.\r\nArgoCD 없이 백엔드 애플리케이션 개발만을 위한 클러스터 구성은 아래의 명령어로 가능합니다.\ncd cluster\r\nsource create-single-cluster.sh\ncluster/create-single-cluster.sh 파일의 내용은 아래와 같습니다.\necho \"\"\r\necho \"=== create Cluster & Ingress-Nginx (Ingress Controller) ===\"\r\necho \"[create] cluster creating...\"\r\nkind create cluster --name fibonacci-cluster --config=cluster.yml\r\n\r\necho \"\"\r\necho \"[create] create ingress-nginx\"\r\nkubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/kind/deploy.yaml\r\n\r\necho \"\"\r\necho \"[wait] wait ingress-nginx standby\"\r\nkubectl wait --namespace ingress-nginx \\\r\n  --for=condition=ready pod \\\r\n  --selector=app.kubernetes.io/component=controller \\\r\n  --timeout=90s\nsingle-cluster.yml 파일의 내용입니다.\nkind: Cluster\r\napiVersion: kind.x-k8s.io/v1alpha4\r\nnodes:\r\n  - role: control-plane\r\n    kubeadmConfigPatches:\r\n      - |\r\n        kind: InitConfiguration\r\n        nodeRegistration:\r\n          kubeletExtraArgs:\r\n            node-labels: \"ingress-ready=true\"\r\n    extraPortMappings:\r\n      - containerPort: 80 # nginx-ingress 가 인식하는 포트\r\n        hostPort: 80 # API 접속시 호스트 PC 의 80 포트로 접속\r\n        protocol: TCP","포트-사용현황#포트 사용현황":"30009 포트\nArgoCD Server\nlocalhost:30009\n80 포트\n백엔드 애플리케이션\nlocalhost/probe/healthcheck\n뒤에서 설명하는 예제들에서 사용하는 예제 애플리케이션입니다. 이번 문서에서는 설치하지 않습니다.","cluster-정의#Cluster 정의":"이 부분은 Kind 에 대한 내용을 파악하는 것인데, 귀찮다면 건너뛰셔도 됩니다.cluster.yml\nkind: Cluster\r\napiVersion: kind.x-k8s.io/v1alpha4\r\nnodes:\r\n  - role: control-plane\r\n    kubeadmConfigPatches:\r\n      - |\r\n        kind: InitConfiguration\r\n        nodeRegistration:\r\n          kubeletExtraArgs:\r\n            node-labels: \"ingress-ready=true\"\r\n    extraPortMappings:\r\n      - containerPort: 30009 # ArgoCD Node Port 를 위한 바인딩\r\n        hostPort: 30009 # ArgoCD 접속시 호스트 PC에서도 30009 로 접속\r\n        protocol: TCP\r\n      - containerPort: 80 # nginx-ingress 가 인식하는 포트\r\n        hostPort: 80 # API 접속시 호스트 PC 의 80 포트로 접속\r\n        protocol: TCP\r\n  - role: worker\r\n# - role: worker\r\n# - role: worker\nKind 클러스터는 실제로 구동될 때 하나의 Container 로 동작합니다. Kind 클러스터를 실행한 후 Docker Desktop 을 열어서 확인하면 실제 생성된 Kind 클러스터를 확인 가능합니다.extraPortMappings[i].containerPort\nKind 클러스터 컨테이너 입장에서 외부로 노출할 포트를 의미합니다. 즉 containerPort 라는 것은 Kind 클러스터 컨테이너의 Port 를 의미합니다.\nextraPortMappings[i].hostPort\n호스트 PC 즉, 개발 PC 내에서 Kind 클러스터로 접속 시에 사용할 Port 를 의미합니다.\nnodes[i].role\ncontrol-plane, worker 등을 지정해줄 수 있습니다. 만약 Cluster 가 하나의 Container 로만 구성되게끔 하려면 worker 를 사용하지 않아도 됩니다.\n경험상 단순한 백엔드 애플리케이션이나 Frontend 애플리케이션을 테스트할 때에는 worker 까지는 필요 없었고 control-plane 하나만으로도 충분히 테스트가 가능했습니다. 다만 ArgoCD 와 함께 구동 시에는 worker 가 적어도 1기 이상은 있어야 합니다.\nnext.js, nuxt.js 의 경우에도 worker 1기 이상은 있어야 파드가 정상적으로 기동되었던 것으로 기억합니다. 요즘 프론트엔드 프레임워크가 옛날 처럼 단순하고 정적인 레벨을 넘어섰기에 리소스도 어느 정도 잡아먹는 듯 합니다.","cluster-생성-cluster-내에-ingress-nginx-연동#cluster 생성, cluster 내에 ingress-nginx 연동":"클러스터는 아래와 같이 생성 가능합니다.\nkind create cluster --name fibonacci-cluster --config=cluster.yml\n이렇게 생성된 클러스터는 아래와 같이 조회 가능합니다.\nkind get clusters\nkind 클러스터가 외부와 통신이 가능하려면 Ingress 컨트롤러가 필요합니다. Ingress 컨트롤러 중 가장 대중적으로 알려진 ingress-nginx 를 kind 클러스터 내에 설치하는 명령어는 아래와 같습니다.\n## ingress-nginx 를 설치합니다.\r\nkubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/kind/deploy.yaml\r\n\r\n\r\n## ingress-nginx 내의 pod 이 로딩 될때 까지 kubectl wait 을 수행합니다.\r\n## 타임아웃은 90초로 주었습니다.\r\nkubectl wait --namespace ingress-nginx \\\r\n  --for=condition=ready pod \\\r\n  --selector=app.kubernetes.io/component=controller \\\r\n  --timeout=90s\n여기까지의 명령어들은 소스코드 리포지터리 내의 cluster/create-cluster.sh 파일 내에 정의해두었고, 그 내용은 아래와 같습니다.\r\ncluster/create-cluster.sh\necho \"\"\r\necho \"=== create Cluster & Ingress-Nginx (Ingress Controller) ===\"\r\necho \"[create] cluster creating...\"\r\nkind create cluster --name fibonacci-cluster --config=cluster.yml\r\n\r\necho \"\"\r\necho \"[create] create ingress-nginx\"\r\nkubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/kind/deploy.yaml\r\n\r\necho \"\"\r\necho \"[wait] wait ingress-nginx standby\"\r\nkubectl wait --namespace ingress-nginx \\\r\n  --for=condition=ready pod \\\r\n  --selector=app.kubernetes.io/component=controller \\\r\n  --timeout=90s","클러스터-내에-argocd-설치#클러스터 내에 ArgoCD 설치":"","argocd-설치#argocd 설치":"argocd 를 설치하기 위해서는 먼저 argocd 라는 이름의 namespace 를 하나 생성해줘야 합니다.\nkubectl create namespace argocd\n이번에는 argocd 를 구성하는 리소스들을 클러스터 내에 생성하도록 kubectl 로 요청하는 절차입니다.\nkubectl -n argocd apply -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml\n이번에는 이렇게 생성된 argocd 관련 리소스 들 에 대해 SSL 옵션을 끄는 명령입니다.\nkubectl -n argocd patch deployment argocd-server --type json -p='[{\"op\":\"replace\",\"path\":\"/spec/template/spec/containers/0/args\",\"value\":[\"/usr/local/bin/argocd-server\",\"--insecure\"]}]'\n생성된 argocd 에서는 admin 이라는 사용자에 대해 초기 password 가 부여되는데 초기 패스워드는 아래의 명령어로 확인 가능합니다.\nkubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath=\"{.data.password}\" | base64 -d\n여기까지 ArgoCD를 모두 설치했습니다. 이렇게 클러스터 내에 설치한 ArgoCD 는 Kind 클러스터 외부, 즉, 호스트 PC(개발PC)에서 접속 가능하려면 Ingress, Nodeport, ClusterIP 등을 이용해 접근이 가능합니다.Ingress 를 사용할 경우 80, 443 포트만 매핑이 가능한데, 80, 443 포트에 대한 / 경로 접근은 애플리케이션을 위해 예약되어 있다. 따라서 이번 예제에서는 ArgoCD 에 Ingress 를 통해 접근하게끔 하지 않을 예정입니다.ArgoCD 를 / 경로로 Ingress 를 통해 ArgoCD 하나를 위해 독자적으로 80, 443 포트로 접근하는 예제가 필요하다면 추후 별도로 Kind 클러스터 세팅에 대해서 정리할 예정이기에 별도의 문서를 참고해주시기 바랍니다.\nClusterIP 를 사용할 경우 클러스터 내에 배포된 argocd-server 의 IP를 알고 있다면 접근이 가능합니다. 이렇게 한다면, 매번 유동적으로 바뀌는 IP를 직접 CLI 로 체크해서 접속해야 하는 불편함이 있습니다.\n이번 예제에서 사용하는 ArgoCD 는  30009 포트에 매핑한 NodePort 를 사용합니다. NodePort를 통해서 ArgoCD가 클러스터 외부와 30009 포트의 / 을 통해 통신을 할 수 있도록 구성했습니다.","nodeport-정의#nodeport 정의":"포트 매핑\n호스트 PC → [클러스터 30009 : NodePort 30009 → 80:8080(argocd-server)]\n위에서 이야기 했듯 이번 예제 프로젝트에서 ArgoCD 는 NodePort 를 통해서 ArgoCD가 클러스터 외부와 30009 포트의 / 경로를 통해 통신을 할 수 있도록 구성했습니다.이렇게 정의한 NodePort 의 역할은 Kind 클러스터 외부(호스트PC)로부터 특정 Port (30009) 로 온 요청을 Kind 클러스터 내부에 argocd-server-nodeport라는 NodePort 로 매핑하고, 이 NodePort 는 ArgoCD 리소스로 연결해주는 역할입니다.\nargocd-nodeport.yml\r\nargocd-nodeport 라는 이름의 NodePort 리소스를 정의한 리소스 정의 파일입니다.\n---\r\napiVersion: v1\r\nkind: Service\r\nmetadata:\r\n  labels:\r\n    app: argocd-server-nodeport\r\n  name: argocd-server-nodeport\r\n  namespace: argocd\r\nspec:\r\n  ports:\r\n  - name: \"80\"\r\n    port: 80\r\n    targetPort: 8080\r\n    nodePort: 30009\r\n    protocol: TCP\r\n  selector:\r\n    app.kubernetes.io/name: argocd-server\r\n  sessionAffinity: None\r\n  type: NodePort\n이렇게 정의한 nodeport 는 아래와 같이 kubectl 로 클러스터에 리소스를 생성하도록 요청할 수 있습니다.\nkubectl apply -f argocd-nodeport.yml","argocd-생성-스크립트#ArgoCD 생성 스크립트":"여기까지 작성한 모든 ArgoCD 생성 스크립트는 cluster/setup-argocd.sh 파일 내에 정의했습니다.cluster/setup-argocd.sh\necho \"\"\r\necho \"[create] namsepace 'argocd'\"\r\nkubectl create namespace argocd\r\n\r\necho \"\"\r\necho \"[install] kubectl apply -f argoprj/argo-cd/.../install.yaml\"\r\nkubectl -n argocd apply -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml\r\n\r\necho \"\"\r\necho \"[configure] --insecure configure\"\r\nkubectl -n argocd patch deployment argocd-server --type json -p='[{\"op\":\"replace\",\"path\":\"/spec/template/spec/containers/0/args\",\"value\":[\"/usr/local/bin/argocd-server\",\"--insecure\"]}]'\r\n\r\necho \"\"\r\necho \"[status] kubectl -n argocd get all\"\r\nkubectl -n argocd get all\r\n\r\necho \"\"\r\necho \"wait(45s) ... \"\r\nsleep 45\r\n\r\necho \"\"\r\necho \"[password!!!] your password\"\r\nkubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath=\"{.data.password}\" | base64 -d\r\n\r\necho \"\"\r\necho \"\"\r\necho \"wait(45s) ... \"\r\nsleep 45\r\n\r\necho \"\"\r\necho \"[setup] nodeport (argocd-nodeport)\"\r\nkubectl apply -f argocd-nodeport.yml\n쉘 스크립트에서 사용하고 있는 argocd-nodeport.yml 파일의 내용은 아래와 같습니다.\napiVersion: v1\r\nkind: Service\r\nmetadata:\r\n  labels:\r\n    app: argocd-server-nodeport\r\n  name: argocd-server-nodeport\r\n  namespace: argocd\r\nspec:\r\n  ports:\r\n  - name: \"80\"\r\n    port: 80\r\n    targetPort: 8080\r\n    nodePort: 30009\r\n    protocol: TCP\r\n  selector:\r\n    app.kubernetes.io/name: argocd-server\r\n  sessionAffinity: None\r\n  type: NodePort","setupsh#setup.sh":"여기까지 작성한 모든 내용들은 cluster/setup.sh 파일에서 호출하고 있습니다.\r\ncluster/setup.sh 파일의 내용은 아래와 같습니다.cluster/setup.sh\necho \"\"\r\necho \">>> [create-cluster.sh]\"\r\nsource create-cluster.sh\r\n\r\necho \"\"\r\necho \">>> [setup-argocd.sh]\"\r\nsource setup-argocd.sh"}},"/setup/reference":{"title":"Reference","data":{"참고했던-스터디-자료들#참고했던 스터디 자료들":"혹시라도 처음으로 쿠버네티스를 스터디해야 하는 분들이거나, 회사에 있는 레거시를 쿠버네티스 기반으로 전환해야 하지만 자료가 없어서 답답하신 분들이 계시다면 아래 자료를 참고해주세요. 저는 혼자 공부하느라 아무것도 모른 채로 몇번 실패해서 읽어본것도 있고  강의를 듣다가 '이건 도저히 안되는 강의네' 하면서 수강을 포기한 강의도 있습니다. 아래에 정리한 자료들은 모두 직접 경험해본 후 실제로 도움이 되었던 자료들입니다.","강의#강의":"한번에 끝내는 CI/CD Docker 부터 GitOps 까지\nKustomize, ArgoCD, EKS 설치 등등 백엔드 개발자가 어렵게 여기는 인프라에 대해 설명이 잘되어 있습니다. 아직 강의를 30% 만 수강해둔 상태여서 더 많은 강의를 들어야 합니다.\n백엔드 개발자를 위한 Kubernetes : 클라우드 네이티브 프로그래밍\n백엔드 개발자 분이 강의를 해주십니다. 강의 내에 해주시는 설명 중에 놓치기 아까운 부분들이 많아서 받아적느라 힘들었습니다. 강의 자료가 PPT에 몇몇 단어나 문장으로만 되어있어서 복습할 때 강의를 한번 더 들어야 한다는 멘탈붕괴에 빠진다는 단점이 있습니다.\n이 강의를 들으신다면, 두 번째 복습때는 꼭 필기를 하셔야 합니다.\n그런데 내용이 정말 알찹니다. 보장합니다.","eks-workshop-studio#EKS Workshop Studio":"Amazon EKS 로 웹 애플리케이션 구축하기\nBuilding Web Applications based on Amazon EKS","블로그#블로그":"blog.naver.com/alice_k106","책#책":"최근 1년 사이에 읽었던 책만 추렸습니다.\n클라우드 네이티브를 위한 쿠버네티스 실전 프로젝트\n핵심만 콕! 쿠버네티스\n쿠버네티스 패턴 - 클라우드 네이티브 애플리케이션 설계와 구현을 위한 24가지 디자인 패턴"}}}